{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class MNISTNet(nn.Module):\n",
    "#     \"\"\"Feedfoward neural network with 1 hidden layer\"\"\"\n",
    "#     def __init__(self):\n",
    "#         super(MNISTNet, self).__init__()\n",
    "        \n",
    "#         self.fc1 = nn.Linear(28*28, 256)\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "#         self.fc3 = nn.Linear(128, 64)        \n",
    "#         self.fc4 = nn.Linear(64, 10)\n",
    "#         self.fc4.is_classifier = True\n",
    "                \n",
    "#     def forward(self, x):\n",
    "#         x = x.view(x.shape[0], -1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = F.relu(self.fc3(x))        \n",
    "#         x = self.fc4(x)\n",
    "#         return F.log_softmax(x, dim=1)\n",
    "    \n",
    "# from torchsummary import summary\n",
    "# model=MNISTNet()\n",
    "# print(\"Model summary\")\n",
    "# print(summary(model, input_size=(1, 28, 28), batch_size=-1))\n",
    "\n",
    "# print(\"Model details\")\n",
    "# for nm, params in model.named_parameters():\n",
    "#     if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "#         print(nm, params.data.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    \"\"\"Evaluate the model's performance on the validation set\"\"\"\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "#     print(\"outputs are \",outputs)\n",
    "    return model.validation_epoch_end(outputs)\n",
    "        \n",
    "    \n",
    "    \n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))        \n",
    "\n",
    "def correct(output, target, topk=(1,)):\n",
    "    \"\"\"Computes how many correct outputs with respect to targets\n",
    "\n",
    "    Does NOT compute accuracy but just a raw amount of correct\n",
    "    outputs given target labels. This is done for each value in\n",
    "    topk. A value is considered correct if target is in the topk\n",
    "    highest values of output.\n",
    "    The values returned are upperbounded by the given batch size\n",
    "\n",
    "    [description]\n",
    "\n",
    "    Arguments:\n",
    "        output {torch.Tensor} -- Output prediction of the model\n",
    "        target {torch.Tensor} -- Target labels from data\n",
    "\n",
    "    Keyword Arguments:\n",
    "        topk {iterable} -- [Iterable of values of k to consider as correct] (default: {(1,)})\n",
    "\n",
    "    Returns:\n",
    "        List(int) -- Number of correct values for each topk\n",
    "    \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        # Only need to do topk for highest k, reuse for the rest\n",
    "        _, pred = output.topk(k=maxk, dim=1, largest=True, sorted=True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(torch.tensor(correct_k.item()))\n",
    "        return res\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    \"\"\"Feedfoward neural network with 1 hidden layer\"\"\"\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()        \n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)        \n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        self.fc4.is_classifier = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))        \n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        top_1, top_5 = correct(out, labels,topk=(1,5))\n",
    "        \n",
    "        top_1=top_1/batch[1].shape[0]\n",
    "        top_5=top_5/batch[1].shape[0]\n",
    "        return {'val_loss': loss, 'val_acc': acc, 'top_1': top_1, 'top_5': top_5}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies        \n",
    "        batch_top_1s = [x['top_1'] for x in outputs]\n",
    "        epoch_top_1 = torch.stack(batch_top_1s).mean()      # Combine top_1        \n",
    "        batch_top_5s = [x['top_5'] for x in outputs]\n",
    "        epoch_top_5 = torch.stack(batch_top_5s).mean()      # Combine top_5\n",
    "        \n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item(),\n",
    "               'val_top_1': epoch_top_1.item(), 'val_top_5': epoch_top_5.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}, val_top_1: {:.4f}, val_top_5: {:.4f}\".format(\n",
    "                                epoch, result['val_loss'], result['val_acc'], \n",
    "                                result['val_top_1'], result['val_top_5']))\n",
    "\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    \"\"\"Train the model using gradient descent\"\"\"\n",
    "    print(\"At train\")\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)        \n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)        \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f7967bdd67445fafd7ad7612155604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5bbc63cbd9498db7f8ab3a4a580298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34dee2eb2a56494cbd32f928c4552d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807b31f38b744a17ab0dec4da9db918e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amirulislam/projects/hbku/spring_2020/independednt_Study_Prof_Samir/venv_indept_study/lib/python3.6/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "data_transforms=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()])\n",
    "\n",
    "\n",
    "dataset = MNIST(root='data/', download=True, transform=data_transforms)\n",
    "# Define test dataset\n",
    "test_dataset = MNIST(root='data/', train=False,transform=data_transforms)\n",
    "\n",
    "\n",
    "\n",
    "val_size = 10000\n",
    "train_size = len(dataset) - val_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size=128\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=1, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=1, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)\n",
    "test_loader = DeviceDataLoader(test_loader, device)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "At train\n",
      "Epoch [0], val_loss: 2.2577, val_acc: 0.3871, val_top_1: 0.3871, val_top_5: 0.6913\n",
      "Epoch [1], val_loss: 1.9926, val_acc: 0.4592, val_top_1: 0.4592, val_top_5: 0.9223\n",
      "Epoch [2], val_loss: 1.0168, val_acc: 0.7391, val_top_1: 0.7391, val_top_5: 0.9803\n",
      "Epoch [3], val_loss: 0.6339, val_acc: 0.8202, val_top_1: 0.8202, val_top_5: 0.9854\n",
      "Epoch [4], val_loss: 0.5141, val_acc: 0.8483, val_top_1: 0.8483, val_top_5: 0.9903\n",
      "Epoch [5], val_loss: 0.4567, val_acc: 0.8661, val_top_1: 0.8661, val_top_5: 0.9921\n",
      "Epoch [6], val_loss: 0.4198, val_acc: 0.8781, val_top_1: 0.8781, val_top_5: 0.9929\n",
      "Epoch [7], val_loss: 0.3959, val_acc: 0.8843, val_top_1: 0.8843, val_top_5: 0.9935\n",
      "Epoch [8], val_loss: 0.3716, val_acc: 0.8926, val_top_1: 0.8926, val_top_5: 0.9947\n"
     ]
    }
   ],
   "source": [
    "model=MNISTNet()\n",
    "if torch.cuda.is_available():\n",
    "    model=model.cuda()    \n",
    "history = [evaluate(model, val_loader)]\n",
    "epochs=20\n",
    "lr=0.01\n",
    "history=fit(epochs, lr, model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate(model, test_loader)\n",
    "print(\"Accuracy of model \",res[\"val_acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_path=\"model_state/mod_untitled.pt\"\n",
    "torch.save(model.state_dict(), model_state_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model details\")\n",
    "for nm, params in model.named_parameters():\n",
    "    if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "        print(nm, \"\\n\",params.data)\n",
    "        print(params.data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights=[]\n",
    "for nm, params in model.named_parameters():\n",
    "    if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "        all_weights.extend(torch.flatten(params.data.detach()))\n",
    "        \n",
    "import plotly.graph_objects as go\n",
    "x = all_weights\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=x,nbinsx=5000)])\n",
    "fig.update_layout(\n",
    "    title=\"Histogram of weight magnitudes for entire neural network\",\n",
    "    xaxis_title=\"Magnitudes\",\n",
    "    yaxis_title=\"Frequency\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.load_state_dict(torch.load(model_state_path))\n",
    "else:\n",
    "    model.load_state_dict(torch.load(model_state_path,map_location=torch.device('cpu')))\n",
    "print(\"Model re-loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_rate=2.25\n",
    "# calculate threshold\n",
    "all_weights=[]\n",
    "for nm, params in model.named_parameters():\n",
    "    if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "        wts=params.data\n",
    "        l=list(wts.flatten().detach().numpy())\n",
    "        all_weights.extend(l)\n",
    "\n",
    "\n",
    "all_weights=torch.tensor(all_weights)\n",
    "all_weights=all_weights.flatten()\n",
    "abs_var=torch.std(torch.abs(all_weights))\n",
    "threshold=abs_var*prune_rate\n",
    "print(\"Threshold is\",threshold)\n",
    "print(\"Max weight = \",max(all_weights), \"\\nMin weight =\",min(all_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            params.data[torch.abs(params.data)<threshold]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for nm, params in model.named_parameters():\n",
    "#     if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "#         print(nm, \"\\n\", params.data)\n",
    "#         print(params.data.shape)\n",
    "#         print(\"*\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights=[]\n",
    "for nm, params in model.named_parameters():\n",
    "    if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "        all_weights.extend(torch.flatten(params.data.detach()))\n",
    "        \n",
    "import plotly.graph_objects as go\n",
    "x = all_weights\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=x,nbinsx=5000)])\n",
    "fig.update_layout(\n",
    "    title=\"Histogram of weight magnitudes for entire neural network\",\n",
    "    xaxis_title=\"Magnitudes\",\n",
    "    yaxis_title=\"Frequency\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights=[]\n",
    "for nm, params in model.named_parameters():\n",
    "    if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "        all_weights.extend(torch.flatten(params.data.detach()))\n",
    "        \n",
    "import plotly.graph_objects as go\n",
    "x = list(filter(lambda a: a != 0, all_weights))\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=x,nbinsx=5000)])\n",
    "fig.update_layout(\n",
    "    title=\"Histogram of weight magnitudes for entire neural network\",\n",
    "    xaxis_title=\"Magnitudes\",\n",
    "    yaxis_title=\"Frequency\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonzero(tensor):\n",
    "    return np.sum(tensor != 0.0)\n",
    "\n",
    "def model_size(model, as_bits=False):\n",
    "    total_params = 0\n",
    "    nonzero_params = 0\n",
    "    for tensor in model.parameters():\n",
    "        t = np.prod(tensor.shape)\n",
    "        nz = nonzero(tensor.detach().cpu().numpy())\n",
    "        if as_bits:\n",
    "            bits = dtype2bits[tensor.dtype]\n",
    "            t *= bits\n",
    "            nz *= bits\n",
    "        total_params += t\n",
    "        nonzero_params += nz\n",
    "    return int(total_params), int(nonzero_params)\n",
    "\n",
    "total_size,nz_size=model_size(model)\n",
    "compression=(total_size-nz_size)/total_size\n",
    "res = evaluate(model, test_loader)\n",
    "print(\"Compression = \",compression)\n",
    "print(\"Accuracy of model \",res[\"val_acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for nm, params in model.named_parameters():\n",
    "#     if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "#         print(nm, \"\\n\", params.data)\n",
    "#         print(params.data.shape)\n",
    "#         print(\"*\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning with fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model_get_mask(model,prune_rate):\n",
    "    \n",
    "    mask_whole_model=[]\n",
    "    all_weights=[]\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            wts=params.data\n",
    "            l=list(wts.flatten().detach().numpy())\n",
    "            all_weights.extend(l)\n",
    "\n",
    "\n",
    "    all_weights=torch.tensor(all_weights)\n",
    "    all_weights=all_weights.flatten()\n",
    "    abs_var=torch.std(torch.abs(all_weights))\n",
    "    threshold=abs_var*prune_rate\n",
    "    \n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            mask_layer=torch.ones(params.shape)            \n",
    "            num_components=params.shape[0]\n",
    "            for index_component in range(num_components):\n",
    "                values=params[index_component]            \n",
    "                re_shaped_values=values.flatten()                \n",
    "                mask_vals = (torch.abs(re_shaped_values)>threshold).float()\n",
    "                mask_vals=mask_vals.reshape(values.shape)\n",
    "                mask_layer[index_component]=mask_vals\n",
    "            mask_whole_model.append(mask_layer)\n",
    "    return mask_whole_model\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.load_state_dict(torch.load(model_state_path))\n",
    "else:\n",
    "    model.load_state_dict(torch.load(model_state_path,map_location=torch.device('cpu')))\n",
    "\n",
    "print(\"Model re-loaded\")\n",
    "mask_whole_model=prune_model_get_mask(model,prune_rate) \n",
    "print(\"Created mask\\n\",mask_whole_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask_model(model,list_mask_whole_model):\n",
    "    mask_layer_count=0\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            mask_layer=list_mask_whole_model[mask_layer_count]\n",
    "            with torch.no_grad():\n",
    "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                mask_layer=mask_layer.to(device)\n",
    "                params.data=params.data*mask_layer            \n",
    "            mask_layer_count+=1\n",
    "    \n",
    "def fit_prune(epochs, lr, model, train_loader, val_loader, \n",
    "        opt_func=torch.optim.SGD,\n",
    "        mask_whole_model=mask_whole_model\n",
    "       ):\n",
    "    \"\"\"Train the model using gradient descent\"\"\"\n",
    "    print(\"At fine tuning (prune + train)\")\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # prune here\n",
    "            apply_mask_model(model,mask_whole_model)\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)        \n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)        \n",
    "    return history\n",
    "\n",
    "epochs=5\n",
    "lr=0.01\n",
    "history=fit_prune(epochs, lr, model, train_loader, val_loader,\n",
    "           mask_whole_model=mask_whole_model)\n",
    "total_size,nz_size=model_size(model)\n",
    "compression=(total_size-nz_size)/total_size\n",
    "res = evaluate(model, test_loader)\n",
    "print(\"Compression = \",compression)\n",
    "print(\"Accuracy of model \",res[\"val_acc\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indept_study",
   "language": "python",
   "name": "indept_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
